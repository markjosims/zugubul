#
# This file is autogenerated by pip-compile with Python 3.8
# by the following command:
#
#    pip-compile
#
accelerate==0.21.0
    # via transformers
aiohttp==3.8.5
    # via
    #   datasets
    #   fsspec
aiosignal==1.3.1
    # via aiohttp
appdirs==1.4.4
    # via pooch
async-timeout==4.0.3
    # via aiohttp
attrs==23.1.0
    # via aiohttp
audioread==3.0.0
    # via librosa
certifi==2023.7.22
    # via requests
cffi==1.15.1
    # via soundfile
charset-normalizer==3.2.0
    # via
    #   aiohttp
    #   requests
click==8.1.7
    # via jiwer
cmake==3.27.2
    # via triton
datasets[audio]==2.14.4
    # via
    #   -r requirements.in
    #   evaluate
decorator==5.1.1
    # via librosa
deepspeed==0.10.1
    # via -r requirements.in
dill==0.3.7
    # via
    #   datasets
    #   evaluate
    #   multiprocess
evaluate==0.4.0
    # via -r requirements.in
filelock==3.12.2
    # via
    #   huggingface-hub
    #   torch
    #   transformers
    #   triton
frozenlist==1.4.0
    # via
    #   aiohttp
    #   aiosignal
fsspec[http]==2023.6.0
    # via
    #   datasets
    #   evaluate
    #   huggingface-hub
hjson==3.1.0
    # via deepspeed
huggingface-hub==0.16.4
    # via
    #   datasets
    #   evaluate
    #   transformers
idna==3.4
    # via
    #   requests
    #   yarl
importlib-metadata==6.8.0
    # via numba
jinja2==3.1.2
    # via torch
jiwer==3.0.2
    # via -r requirements.in
joblib==1.3.2
    # via
    #   librosa
    #   scikit-learn
lazy-loader==0.3
    # via librosa
librosa==0.10.0.post2
    # via datasets
lit==16.0.6
    # via triton
llvmlite==0.40.1
    # via numba
markupsafe==2.1.3
    # via jinja2
mpmath==1.3.0
    # via sympy
msgpack==1.0.5
    # via librosa
multidict==6.0.4
    # via
    #   aiohttp
    #   yarl
multiprocess==0.70.15
    # via
    #   datasets
    #   evaluate
networkx==3.1
    # via torch
ninja==1.11.1
    # via deepspeed
numba==0.57.1
    # via librosa
numpy==1.24.4
    # via
    #   -r requirements.in
    #   accelerate
    #   datasets
    #   deepspeed
    #   evaluate
    #   librosa
    #   numba
    #   pandas
    #   pyarrow
    #   scikit-learn
    #   scipy
    #   soxr
    #   transformers
nvidia-cublas-cu11==11.10.3.66
    # via
    #   nvidia-cudnn-cu11
    #   nvidia-cusolver-cu11
    #   torch
nvidia-cuda-cupti-cu11==11.7.101
    # via torch
nvidia-cuda-nvrtc-cu11==11.7.99
    # via torch
nvidia-cuda-runtime-cu11==11.7.99
    # via torch
nvidia-cudnn-cu11==8.5.0.96
    # via torch
nvidia-cufft-cu11==10.9.0.58
    # via torch
nvidia-curand-cu11==10.2.10.91
    # via torch
nvidia-cusolver-cu11==11.4.0.1
    # via torch
nvidia-cusparse-cu11==11.7.4.91
    # via torch
nvidia-nccl-cu11==2.14.3
    # via torch
nvidia-nvtx-cu11==11.7.91
    # via torch
packaging==23.1
    # via
    #   accelerate
    #   datasets
    #   deepspeed
    #   evaluate
    #   huggingface-hub
    #   pooch
    #   transformers
pandas==2.0.3
    # via
    #   datasets
    #   evaluate
pooch==1.6.0
    # via librosa
psutil==5.9.5
    # via
    #   accelerate
    #   deepspeed
py-cpuinfo==9.0.0
    # via deepspeed
pyarrow==12.0.1
    # via datasets
pyaudio==0.2.13
    # via -r requirements.in
pycparser==2.21
    # via cffi
pydantic==1.10.12
    # via deepspeed
pydub==0.25.1
    # via -r requirements.in
pympi-ling==1.70.2
    # via -r requirements.in
python-dateutil==2.8.2
    # via pandas
pytz==2023.3
    # via pandas
pyyaml==6.0.1
    # via
    #   accelerate
    #   datasets
    #   huggingface-hub
    #   transformers
rapidfuzz==2.13.7
    # via jiwer
regex==2023.8.8
    # via transformers
requests==2.31.0
    # via
    #   datasets
    #   evaluate
    #   fsspec
    #   huggingface-hub
    #   pooch
    #   responses
    #   transformers
responses==0.18.0
    # via evaluate
safetensors==0.3.2
    # via transformers
scikit-learn==1.3.0
    # via librosa
scipy==1.10.1
    # via
    #   -r requirements.in
    #   librosa
    #   scikit-learn
six==1.16.0
    # via python-dateutil
soundfile==0.12.1
    # via
    #   datasets
    #   librosa
soxr==0.3.5
    # via librosa
sympy==1.12
    # via torch
threadpoolctl==3.2.0
    # via scikit-learn
tokenizers==0.13.3
    # via transformers
tomli==2.0.1
    # via -r requirements.in
torch==2.0.1
    # via
    #   -r requirements.in
    #   accelerate
    #   deepspeed
    #   transformers
    #   triton
tqdm==4.66.1
    # via
    #   datasets
    #   deepspeed
    #   evaluate
    #   huggingface-hub
    #   transformers
transformers[torch]==4.31.0
    # via -r requirements.in
triton==2.0.0
    # via torch
typing-extensions==4.7.1
    # via
    #   huggingface-hub
    #   librosa
    #   pydantic
    #   torch
tzdata==2023.3
    # via pandas
urllib3==2.0.4
    # via
    #   requests
    #   responses
wheel==0.41.1
    # via
    #   nvidia-cublas-cu11
    #   nvidia-cuda-cupti-cu11
    #   nvidia-cuda-runtime-cu11
    #   nvidia-curand-cu11
    #   nvidia-cusparse-cu11
    #   nvidia-nvtx-cu11
xxhash==3.3.0
    # via
    #   datasets
    #   evaluate
yarl==1.9.2
    # via aiohttp
zipp==3.16.2
    # via importlib-metadata

# The following packages are considered to be unsafe in a requirements file:
# setuptools
